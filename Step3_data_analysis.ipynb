{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7l1ZVgY3Cxwg"},"outputs":[],"source":["from my_utils import emotion_dict, sentiment_dict, film_frames_dict\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy.stats import spearmanr, pearsonr, f_oneway\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h93wKVbz78lu"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","folder = '/content/drive/My Drive/Colab Notebooks/Dissertation'\n","\n","os.chdir(folder)\n","\n","output_dir = './Datasets'\n","results_dir = './Results'\n","film_keys = list(emotion_dict.keys())\n","datasets = ['frame_level', 'video_level']\n","results = ['eda', 'stats_analysis','modelling']\n","feature_group = ['rgb_hsv','audio','optical_flow']\n","\n","for dataset in datasets:\n","    os.makedirs(os.path.join(results_dir, dataset), exist_ok=True)\n","    for results_type in results:\n","        os.makedirs(os.path.join(results_dir, dataset, results_type), exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"pnYpNKG978lu"},"source":["# 2. Data Analysis"]},{"cell_type":"markdown","metadata":{"id":"vfNlBINx78lv"},"source":["#### Function to load feature sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oUpsgIIk78lv"},"outputs":[],"source":["# obtain the frame-level and video-level feature sets\n","def load_datasets(frame_level_path, video_level_path):\n","    if os.path.exists(frame_level_path):\n","        frame_df = pd.read_csv(frame_level_path)\n","    else:\n","        frame_df = None\n","        print (f\"File {frame_level_path} not found\")\n","\n","    if os.path.exists(video_level_path):\n","        video_df = pd.read_csv(video_level_path)\n","    else:\n","        video_df = None\n","        print (f\"File {video_level_path} not found\")\n","\n","    return frame_df, video_df\n","\n","# obtain the frame-level and video-level feature sets based on the feature group (rgb_hsv, audio, optical_flow)\n","\n","def get_feature_group_datasets(feature_group):\n","    # call load_datasets above\n","    frame_df, video_df = load_datasets(os.path.join(output_dir, f\"{datasets[0]}/features_{feature_group}_df.csv\"),\n","                                       os.path.join(output_dir, f\"{datasets[1]}/features_{feature_group}_df.csv\"))\n","\n","    v_shape = ()\n","    f_shape = ()\n","    feature_cols = []\n","\n","    if video_df is not None:\n","        feature_cols = [col for col in video_df.columns if col not in [\"video_id\", \"emotion\", \"sentiment\"]]\n","        v_shape = video_df.shape\n","\n","    if frame_df is not None:\n","        f_shape = frame_df.shape\n","\n","        feature_cols = [col for col in frame_df.columns if col not in [\"video_id\", \"frame_id\", \"emotion\", \"sentiment\"]]\n","\n","    print(f\"Dataframes shape for {feature_group}: frame-level -> {f_shape}, video-level -> {v_shape}\")\n","\n","    return frame_df, video_df, feature_cols"]},{"cell_type":"markdown","metadata":{"id":"4Rkhh5Fn78lv"},"source":["#### Box Plot Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SU_jWmi_78lw"},"outputs":[],"source":["# get a discrete clour palette for the emotions\n","def get_discrete_colour_palette(unique_emotions):\n","    colour_palette = sns.color_palette(\"tab10\", len(unique_emotions))  # using tab10 for discrete colours\n","    return dict(zip(unique_emotions, colour_palette))\n","\n","# generate box plots\n","def plot_boxplot_by_emotion(df, feature_columns, f_set_id, feature_group, results_dir=results_dir, display_plot=False):\n","\n","    unique_emotions = df[\"emotion\"].unique() # get the Seven-emotion labels\n","    emotion_palette = get_discrete_colour_palette(unique_emotions)\n","\n","    plt.figure(figsize=(8, 6))\n","    df_melted = df.melt(id_vars=[\"emotion\"], value_vars=feature_columns, var_name=\"Feature\", value_name=\"Value\") # keep emotion column as the identifier and features are the variables\n","    sns.boxplot(x=\"Feature\", y=\"Value\", hue=\"emotion\", data=df_melted, palette=emotion_palette)\n","    plt.xticks(rotation=45)\n","    plt.title(f\"Boxplots of '{f_set_id}' by Emotion\")\n","    plt.legend(title=\"Emotion\", bbox_to_anchor=(1.05, 1), loc='upper left')\n","    plt.savefig(os.path.join(results_dir, f\"boxplot_by_emotion_{feature_group}_{f_set_id}.png\"), bbox_inches='tight')\n","\n","    if display_plot:\n","        plt.show()\n","\n","    plt.close()"]},{"cell_type":"markdown","metadata":{"id":"l8gvtjdP78lw"},"source":["#### Correlation Analysis Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dPzz7ANb78lw"},"outputs":[],"source":["# correlations between features and labels\n","def correlation_analysis(df, feature_columns, label_column, feature_group, results_dir=results_dir, display_plot=False):\n","\n","    # Convert emotion labels to numeric values\n","    le = LabelEncoder()\n","    df[\"encoded_emotion\"] = le.fit_transform(df[label_column])\n","\n","    # Compute correlations\n","    correlations = {}\n","\n","    for feature in feature_columns:\n","        pearson_corr, _ = pearsonr(df[feature],  df[\"encoded_emotion\"])\n","        spearman_corr, _ = spearmanr(df[feature],  df[\"encoded_emotion\"])\n","        correlations[feature] = {\"Pearson\": pearson_corr, \"Spearman\": spearman_corr}\n","\n","    correlation_df = pd.DataFrame(correlations).T\n","    correlation_df.to_csv(os.path.join(results_dir, f\"correlation_analysis_by_{label_column}_{feature_group}.csv\"))\n","\n","    # plot heatmap of correlation coefficient\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(correlation_df, annot=True, cmap=\"coolwarm\", linewidths=0.5)\n","    plt.title(f\"Heatmap of feature correlation with '{label_column}' label\")\n","    plt.savefig(os.path.join(results_dir, f\"correlation_heatmap_by_{label_column}_{feature_group}.png\"), bbox_inches='tight')\n","    if display_plot:\n","        plt.show()\n","    plt.close()\n","\n","# correlations between the features\n","def plot_feature_correlation_heatmap(df, feature_columns, feature_group, results_dir=results_dir, threshold=0.7, display_plot=False):\n","\n","    # compute correlation matrix\n","    corr_matrix = df[feature_columns].corr()\n","\n","    # plot heatmap of correlations among features\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", linewidths=0.5, fmt=\".2f\")\n","    plt.title(\"Feature Correlation Heatmap\")\n","    plt.savefig(os.path.join(results_dir, f\"correlation_heatmap_features_{feature_group}.png\"), bbox_inches='tight')\n","    if display_plot:\n","        plt.show()\n","    plt.close()\n","\n","    # identify highly correlated pairs\n","    high_corr_pairs = []\n","    for i in range(len(corr_matrix.columns)):\n","        for j in range(i + 1, len(corr_matrix.columns)):\n","            if abs(corr_matrix.iloc[i, j]) > threshold: # using a threshold of 0.7\n","                high_corr_pairs.append((corr_matrix.index[i], corr_matrix.index[j], corr_matrix.iloc[i, j]))\n","\n","    # save highly correlated pairs to a file\n","    high_corr_df = pd.DataFrame(high_corr_pairs, columns=[\"Feature 1\", \"Feature 2\", \"Correlation\"])\n","    high_corr_df.to_csv(os.path.join(results_dir, f\"highly_correlated_features_{feature_group}.csv\"), index=False)"]},{"cell_type":"markdown","metadata":{"id":"y_DPpliI78lw"},"source":["#### Statistical Analysis Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"44cP7oY478lw"},"outputs":[],"source":["def bootstrap_anova(df, label_column, feature, n_iterations, sample_size):\n","\n","    f_values, p_values = [], []\n","\n","    for _ in range(n_iterations):\n","        subset_df = df.sample(frac=sample_size, replace=False)  # bootstrap sample\n","        groups = [group[feature].dropna().values for name, group in subset_df.groupby(label_column)] # group feature vectors by emotion label\n","\n","        if all(len(g) > 1 for g in groups):  # ensure groups have enough samples\n","            f_val, p_val = f_oneway(*groups) # one way ANOVA\n","            f_values.append(f_val)\n","            p_values.append(p_val)\n","\n","    return np.mean(f_values), np.mean(p_values) # return mean values from all iterations"]},{"cell_type":"markdown","metadata":{"id":"qERGhdT_78lx"},"source":["## 2.1 Data Visualisations\n","Plots saved to Results folder (both for frame-level and video-level features)\n"]},{"cell_type":"markdown","metadata":{"id":"EPJiDxwe78lx"},"source":[" #### 2.1.1 RGB_HSV Features\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_pSEUSYV78lx"},"outputs":[],"source":["frame_df, video_df, feature_cols = get_feature_group_datasets(feature_group[0])\n","\n","for dataset in datasets:\n","\n","    if dataset == 'frame_level':\n","         df = frame_df\n","    else:\n","        df = video_df\n","\n","    if df is not None:\n","        subset_feature_cols = {\n","            \"Colourfulness\": [\"colourfulness\"],\n","            \"Red\": [col for col in feature_cols if col.startswith(\"R_\")],\n","            \"Green\": [col for col in feature_cols if col.startswith(\"G_\")],\n","            \"Blue\": [col for col in feature_cols if col.startswith(\"B_\")],\n","            \"Hue\": [col for col in feature_cols if col.startswith(\"H_\")],\n","            \"Saturation\": [col for col in feature_cols if col.startswith(\"S_\")],\n","            \"Value\": [col for col in feature_cols if col.startswith(\"V_\")]\n","        }\n","\n","        # generate box plots with feature names\n","        for subset_f in subset_feature_cols.keys():\n","            plot_boxplot_by_emotion(df, subset_feature_cols[subset_f], subset_f,\n","                                    feature_group = feature_group[0],\n","                                    results_dir=os.path.join(results_dir,dataset,'eda'),\n","                                    display_plot=True)\n","    else:\n","        print(\"No colour feature files found\")\n"]},{"cell_type":"markdown","metadata":{"id":"qitkaRfR78lx"},"source":[" #### 2.1.2 Audio Features\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGVCodzP78lx"},"outputs":[],"source":["frame_df, video_df, feature_cols = get_feature_group_datasets(feature_group[1])\n","\n","for dataset in datasets:\n","\n","    if dataset == 'frame_level':\n","        df = frame_df\n","    else:\n","        df = video_df\n","\n","    if df is not None:\n","\n","        subset_feature_cols = {\n","        \"Spectral centroid\": [\"spectral_centroid\"],\n","        \"Spectral bandwidth\": [\"spectral_bandwidth\"],\n","        \"RMS Energy\": [\"rms_energy\"],\n","        \"Zero Crossing Rate\": [\"zero_crossing_rate\"],\n","        \"Amplitude envelope\": [\"amplitude_envelope\"],\n","        \"Chroma\": [\"chroma_mean\"],\n","        \"MFCCS\": [\"mfccs_mean\"],\n","        \"Delta MFCCS\": [\"delta_mfccs_mean\"],\n","        \"Delta2 MFCCS\": [\"delta2_mfccs_mean\"] }\n","\n","        # generate box plots with feature names\n","        for subset_f in subset_feature_cols.keys():\n","            plot_boxplot_by_emotion(df, subset_feature_cols[subset_f], subset_f,\n","                                    feature_group = feature_group[1],\n","                                    results_dir=os.path.join(results_dir,dataset,'eda'),\n","                                    display_plot=True)\n","\n","    else:\n","        print(\"No audio features files found\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dCtnzXW278lx"},"source":[" #### 2.1.3 Motion (Optical Flow) Features\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AR74hcYn78lx"},"outputs":[],"source":["frame_df, video_df, feature_cols = get_feature_group_datasets(feature_group[2])\n","\n","subset_feature_cols = {}\n","for f in feature_cols:\n","    subset_feature_cols[f] = f\n","\n","for dataset in datasets:\n","\n","    if dataset == 'frame_level':\n","        df = frame_df\n","    else:\n","        df = video_df\n","\n","    if df is not None:\n","\n","        for subset_f in subset_feature_cols:\n","            plot_boxplot_by_emotion(df, subset_feature_cols[subset_f], subset_f,\n","                                    feature_group = feature_group[2],\n","                                    results_dir=os.path.join(results_dir,dataset,'eda'),\n","                                    display_plot=True)\n","\n","    else:\n","        print(\"No motion features files found\")\n"]},{"cell_type":"markdown","metadata":{"id":"Rm83r8Kg78lx"},"source":["## 2.2 Correlation Analysis\n","Analysing both for 'emotion' label and 'sentiment' label"]},{"cell_type":"markdown","metadata":{"id":"R4zekZVU78lx"},"source":[" #### 2.2.1 RGB_HSV Features\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aw56It9g78lx"},"outputs":[],"source":["frame_df, video_df, feature_cols = get_feature_group_datasets(feature_group[0])\n","\n","for dataset in datasets:\n","\n","    if dataset == 'frame_level':\n","         df = frame_df\n","    else:\n","        df = video_df\n","\n","    feature_cols = [col for col in df.columns if col not in [\"video_id\", \"frame_id\", \"emotion\", \"sentiment\"]]\n","\n","    correlation_analysis(df, feature_cols, \"emotion\", feature_group = feature_group[0], results_dir=os.path.join(results_dir,dataset,'stats_analysis'), display_plot=False)\n","    correlation_analysis(df, feature_cols, \"sentiment\", feature_group = feature_group[0], results_dir=os.path.join(results_dir,dataset,'stats_analysis'), display_plot=False)\n","    plot_feature_correlation_heatmap(df, feature_cols, feature_group = feature_group[0], results_dir=os.path.join(results_dir,dataset,'stats_analysis'), display_plot=True)"]},{"cell_type":"markdown","metadata":{"id":"B5uAdLMf78lx"},"source":[" #### 2.2.2 Audio Features\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-gZM1bJ78lx"},"outputs":[],"source":["\n","frame_df, video_df, feature_cols = get_feature_group_datasets(feature_group[1])\n","\n","for dataset in datasets:\n","\n","    if dataset == 'frame_level':\n","         df = frame_df\n","    else:\n","        df = video_df\n","\n","    feature_cols = [col for col in df.columns if col not in [\"video_id\", \"frame_id\", \"emotion\", \"sentiment\", \"encoded_emotion\"]\n","                        and not col.startswith(\"chroma\") and not col.startswith(\"mfcc\") and not col.startswith(\"delta_mfcc\") and not col.startswith(\"delta2_mfcc\")]\n","    feature_cols_mfcc = [col for col in df.columns if col.startswith(\"mfcc\") or col.startswith(\"delta_mfcc\") or col.startswith(\"delta2_mfcc\")]\n","    feature_cols_chroma = [col for col in df.columns if col.startswith(\"chroma\") ]\n","\n","    if df is not None:\n","        feature_group = \"audio_features\"\n","        correlation_analysis(df, feature_cols, \"emotion\", feature_group, results_dir=os.path.join(results_dir,dataset,'stats_analysis'), display_plot=False)\n","        correlation_analysis(df, feature_cols, \"sentiment\", feature_group, results_dir=os.path.join(results_dir,dataset,'stats_analysis'), display_plot=False)\n","        plot_feature_correlation_heatmap(df, feature_cols, feature_group, results_dir=os.path.join(results_dir,dataset,'stats_analysis'), display_plot=True)\n","\n","        # uncomment for mfcc features / chroma features\n","\n","        '''\n","        feature_group = \"audio_features_mfcc\"\n","        correlation_analysis(df, feature_cols_mfcc, \"emotion\", feature_group, results_dir=os.path.join(results_dir,dataset,'stats_analysis'), display_plot=True)\n","        correlation_analysis(df, feature_cols_mfcc, \"sentiment\", feature_group, results_dir=os.path.join(results_dir,dataset,'stats_analysis'), display_plot=True)\n","        plot_feature_correlation_heatmap(df, feature_cols_mfcc, feature_group, results_dir=os.path.join(results_dir,dataset,'stats_analysis'), display_plot=True)\n","\n","        feature_group = \"audio_features_chroma\"\n","        correlation_analysis(df, feature_cols_chroma, \"emotion\", feature_group, results_dir=os.path.join(results_dir,dataset,'stats_analysis'), display_plot=True)\n","        correlation_analysis(df, feature_cols_chroma, \"sentiment\", feature_group, results_dir=os.path.join(results_dir,dataset,'stats_analysis'), display_plot=True)\n","        plot_feature_correlation_heatmap(df, feature_cols_chroma, feature_group, results_dir=os.path.join(results_dir,dataset,'stats_analysis'), display_plot=True)'\n","        '''\n"]},{"cell_type":"markdown","metadata":{"id":"vQfv0Zuf78lx"},"source":["## 2.3. Statistical Analysis\n","Analysing both for 'emotion' label and 'sentiment' label"]},{"cell_type":"markdown","metadata":{"id":"HxS8DKkE78ly"},"source":["#### 2.3.1 RGB_HSV features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hv0XHVWN78ly"},"outputs":[],"source":["frame_df, video_df, feature_cols = get_feature_group_datasets(feature_group[0]) # selecting RGB_HSV features\n","\n","# uncomment depending on what label to use\n","label_column = 'emotion'\n","#label_column = 'sentiment'\n","\n","# uncomment depending on what dataset to use and change sample size accordingly\n","'''\n","dataset = 'frame_level'\n","df = frame_df\n","sample_size = 0.01\n","n_iterations = 1000\n","'''\n","dataset = 'video_level'\n","df = video_df\n","sample_size = 1.0\n","n_iterations = 1\n","\n","results = []\n","\n","print(f\"Bootstrapped ANOVA Results for {feature_group[0]} Features:\")\n","for feature in feature_cols:\n","    f, p = bootstrap_anova(df, label_column, feature, n_iterations, sample_size)\n","    print(f\"{feature}: Mean F-value = {f:.2f}, Mean p-value = {p:.4f}\")\n","\n","    # Append to results list\n","    results.append({\n","            \"Feature\": feature,\n","            \"Mean F-value\": round(f, 2),\n","            \"Mean p-value\": round(p, 4)\n","    })\n","\n","\n","results_df = pd.DataFrame(results)\n","\n","# save results to a csv file\n","results_df.to_csv(os.path.join(os.path.join(results_dir,dataset,'stats_analysis'),\n","                                f\"bootstrap_anova_sample_size_{sample_size}_{label_column}_{feature_group[0]}.csv\"))\n"]},{"cell_type":"markdown","metadata":{"id":"T59fffmi78ly"},"source":["#### 2.3.2 Audio features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sTTW2Oxd78ly"},"outputs":[],"source":["frame_df, video_df, feature_cols = get_feature_group_datasets(feature_group[1]) # selecting audio features\n","\n","# uncomment depending on what label to use\n","label_column = 'emotion'\n","#label_column = 'sentiment'\n","\n","# uncomment depending on what dataset to use and change sample size accordingly\n","'''\n","dataset = 'frame_level'\n","df = frame_df\n","sample_size = 0.01\n","n_iterations = 1000\n","'''\n","\n","dataset = 'video_level'\n","df = video_df\n","sample_size = 1.0\n","n_iterations = 1\n","\n","results = []\n","\n","print(f\"Bootstrapped ANOVA Results for {feature_group[1]} Features:\")\n","for feature in feature_cols:\n","    f, p = bootstrap_anova(df, label_column, feature, n_iterations, sample_size)\n","    print(f\"{feature}: Mean F-value = {f:.2f}, Mean p-value = {p:.4f}\")\n","\n","    # Append to results list\n","    results.append({\n","            \"Feature\": feature,\n","            \"Mean F-value\": round(f, 2),\n","            \"Mean p-value\": round(p, 4)\n","    })\n","\n","results_df = pd.DataFrame(results)\n","\n","# save results to a csv file\n","results_df.to_csv(os.path.join(os.path.join(results_dir,dataset,'stats_analysis'),\n","                                f\"bootstrap_anova_sample_size_{sample_size}_{label_column}_{feature_group[1]}.csv\"))"]},{"cell_type":"markdown","metadata":{"id":"v38_zSQ_78ly"},"source":["#### 2.3.3 Motion (Optical Flow) Features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KV7SoW-q78ly"},"outputs":[],"source":["frame_df, video_df, feature_cols = get_feature_group_datasets(feature_group[2]) # selecting motion features\n","\n","# uncomment depending on what label to use\n","label_column = 'emotion'\n","#label_column = 'sentiment'\n","\n","# uncomment depending on what dataset to use and change sample size accordingly\n","'''\n","dataset = 'frame_level'\n","df = frame_df\n","sample_size = 0.01\n","n_iterations = 1000\n","'''\n","\n","dataset = 'video_level'\n","df = video_df\n","sample_size = 1.0\n","n_iterations = 1\n","\n","results = []\n","\n","print(f\"Bootstrapped ANOVA Results for {feature_group[2]} Features:\")\n","for feature in feature_cols:\n","    f, p = bootstrap_anova(df, label_column, feature, n_iterations, sample_size)\n","    print(f\"{feature}: Mean F-value = {f:.2f}, Mean p-value = {p:.4f}\")\n","\n","    # Append to results list\n","    results.append({ \"Feature\": feature,\n","                    \"Mean F-value\": round(f, 2),\n","                    \"Mean p-value\": round(p, 4)})\n","\n","results_df = pd.DataFrame(results)\n","\n","# save results to a csv file\n","results_df.to_csv(os.path.join(os.path.join(results_dir,dataset,'stats_analysis'),\n","                                f\"bootstrap_anova_sample_size_{sample_size}_{label_column}_{feature_group[2]}.csv\"))"]}],"metadata":{"colab":{"collapsed_sections":["pRqUq8AvG4wi"],"provenance":[{"file_id":"1lBl443RsMiy9SjbfZhyWE4RQOIWH0e78","timestamp":1745659315867}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}